{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 The Computational Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Topographic feature maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1\n",
    "Read `test0.jpg` from $640x480$ directory, and split the image into 3 channels of RGB namely `r`, `g`, `b`. To compute the intensity `I`, use the formula $I = (r + g + b)/3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = plt.imread('test0.jpg')\n",
    "r = img[:, :, 0]\n",
    "g = img[:, :, 1]\n",
    "b = img[:, :, 2]\n",
    "I = (r + g + b) / 3\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2\n",
    "Normalize `r`, `g`, `b` by `I`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def normalizeImage(n, d, t):\n",
    "#     return np.reshape([i/j if j > t else 0 for i,j in zip(np.nditer(n), np.nditer(d))], d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalizeImage(nom, denom, threshold):\n",
    "    nom = np.copy(nom)\n",
    "    yes = np.where(denom > threshold)\n",
    "    nom[np.where(denom <= threshold)] = 0\n",
    "    nom[yes] = nom[yes] / denom[yes]\n",
    "    return nom\n",
    "\n",
    "threshold = 0.1*np.max(I)\n",
    "r = normalizeImage(r, I, threshold)\n",
    "b = normalizeImage(b, I, threshold)\n",
    "g = normalizeImage(g, I, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3\n",
    "Compute `R`, `G`, `B`, `Y` as mentioned in the paper using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R = r - (g + b) / 2\n",
    "G = g - (r + b) / 2\n",
    "B = b - (r + g) / 2\n",
    "Y = (r + g) / 2 - np.abs(r - g) / 2 - b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4\n",
    "Design Gabor filters using `getGaborKernel()` from OpenCV. Select parameters for kernel size, sigma ($\\sigma$), theta ($\\theta$) and lambd ($\\lambda$) to find appropriate filters for four orientations ($\\theta = \\{0^{\\circ}, 45^{\\circ}, 90^{\\circ}, 135^{\\circ}\\}$). We may fix gamma ($\\gamma$) and phi ($\\phi$) with $0.5$ and $0$ respectively. Save your designed Gabor filters to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gabors = []\n",
    "for i, theta in enumerate(range(0, 180, 45)):\n",
    "    gabors.append(cv2.getGaborKernel((12, 16), sigma=1, theta=theta, lambd=10, gamma=.5, psi=0))\n",
    "    plt.imsave('114_gabor_{}.png'.format(i), gabors[-1], cmap='gray')\n",
    "    ax = plt.subplot(221+i)\n",
    "    ax.set_title('theta = {}'.format(theta))\n",
    "    ax.imshow(gabors[i], cmap='gray')\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.5\n",
    "Convolve the gray image (to convert an image to gray image, use: `cv2.cvtColor()`) with the Gabor filters from previous step using `cv2.filter2D()`. Save your output images from four orientations to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gabored = []\n",
    "for i, gabor in enumerate(gabors):\n",
    "    gabored.append(cv2.filter2D(img_gray, -1, gabor))\n",
    "    ax = plt.subplot(221+i)\n",
    "    ax.imshow(gabored[i], cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title('theta = {}'.format(range(0, 180, 45)[i]))\n",
    "    plt.imsave('115_gabored_{}.png'.format(i), gabored[-1], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.6\n",
    "Now, we are ready to go! Apply cv2.pyDown() to create Gaussian pyramids in eight octaves for all maps that we have created. (The scales mentioned in the paper start from scale zero.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makePyramids(img):\n",
    "    pyramids = [img] # original image is octave zero\n",
    "    for i in range(7):\n",
    "        pyramids.append(cv2.pyrDown(pyramids[-1]))\n",
    "    return pyramids\n",
    "\n",
    "Rpyr = makePyramids(R)\n",
    "Gpyr = makePyramids(G)\n",
    "Bpyr = makePyramids(B)\n",
    "Ypyr = makePyramids(Y)\n",
    "Ipyr = makePyramids(I)\n",
    "Opyrs = [makePyramids(gabor) for gabor in gabors]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Multi-scale center-surround differences\n",
    "Set fine scales using center $c$ at $c \\in \\{2, 3, 4\\}$ and coarse scales as surround $s = c + \\delta$, with $Î´ \\in \\{3, 4\\}$. Therefore, we get 6 pairs of $(c, s)$ across different octaves as $\\{2, 5\\}, \\{2, 6\\}, \\{3, 6\\}, \\{3, 7\\}, \\{4, 7\\}, \\{4, 8\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cs = np.asarray([(2,5), (2,6), (3,6), (3,7), (4,7), (4,8)])-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1\n",
    "Compute $\\mathcal{I}(c, s)$, $\\mathcal{RG}(c, s)$, $\\mathcal{BY}(c, s)$ as defined in equation $(1)$, $(2)$ and $(3)$ as described in the paper. In order to perform operations across the different scales, you can use `cv2.resize()` to linearly interpolate the map to any scale.\n",
    "\n",
    "$$\\mathcal{I}(c,s) = |I(c) \\ominus I(s)| \\quad (1)$$\n",
    "$$\\mathcal{RG}(c,s) = |(R(c) - G(c)) \\ominus (G(s) - R(s))| \\quad (2)$$\n",
    "$$\\mathcal{BY}(c, s) = |(B(c) - Y(c)) \\ominus (Y(s) - B(s))| \\quad (3)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csab = lambda c,s,a,b = np.zeros(8): (a[c]-b[c]) - cv2.resize(-1*b[s]+a[s],a[c].shape[::-1])\n",
    "Ics = list(csab(c,s,Ipyr) for c,s in cs)\n",
    "RGcs = list(csab(c,s,Rpyr,Gpyr) for c,s in cs)\n",
    "BYcs = list(csab(c,s,Bpyr,Ypyr) for c,s in cs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2\n",
    "Similarly, compute $O(c,s,\\theta)$ as in equation $(4)$.\n",
    "\n",
    "$$O(c,s,\\theta) = |O(c,\\theta) \\ominus O(s,\\theta)| \\quad (4)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Otcs = [[csab(c,s,Opyr) for c,s in cs] for Opyr in Opyrs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3\n",
    "Now, we get 6 maps for intensity, 12 maps for color and 24 for orientation. Apply normalization $\\mathcal{N}(\\cdot)$ to each map using the same range for all maps. (Read about normalization and how to do it in the paper!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import argrelextrema\n",
    "def normalize(img):\n",
    "    M = np.max(img)\n",
    "    m = np.mean([m for m in img[argrelextrema(img, np.greater)] if m != M])\n",
    "    return np.copy(img) * ((M - m) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Ics = [normalize(img) for img in Ics]\n",
    "RGcs = [normalize(img) for img in RGcs]\n",
    "BYcs = [normalize(img) for img in BYcs]\n",
    "Otcs = [[normalize(img) for img in Ocs] for Ocs in Otcs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Across-scale combinations and normalization\n",
    "We will combine maps from different scales and modalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1\n",
    "In order to combine maps from different scales we select the scale at $\\sigma = 4$. Again, we can use `cv2.resize()` to combine maps by their features as shown in equations $(5)$, $(6)$ and $(7)$.\n",
    "\n",
    "$$\\bar{\\mathcal{I}} = \\oplus^4_{c=2} \\oplus^{c+4}_{s=c+3} \\mathcal{N}(I(c,s)) \\quad (5)$$\n",
    "\n",
    "$$\\bar{C} = \\oplus^4_{c=2} \\oplus^{c+4}_{s=c+3} [\\mathcal{N}(\\mathcal{RG}(c,s)) + \\mathcal{N}(\\mathcal{BY}(c,s))] \\quad (6)$$\n",
    "\n",
    "$$\\bar{O} = \\sum_{\\theta \\in \\{0^{\\circ},45^{\\circ},90^{\\circ},135^{\\circ}\\}} \\mathcal{N} \\left( \\oplus^4_{c=2} \\oplus^{c+4}_{s=c+3} \\mathcal{N}(O(c,s,\\theta)) \\right) \\quad (6)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def addition(imgs, size):\n",
    "    imgs = [cv2.resize(img, size[::-1]) for img in imgs]\n",
    "    return np.sum(imgs, 0)\n",
    "Ibar = addition(Ics, Ics[3].shape)\n",
    "Cbar = addition([RGcs[i] + BYcs[i] for i in range(len(RGcs))], RGcs[3].shape)\n",
    "Obar = np.sum([normalize(addition(Ocs, Ics[3].shape)) for Ocs in Otcs], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.3.2\n",
    "The final saliency map can be obtained using equation $(9)$. Save the saliency map to a file. (You can up-scale the saliency map to the original image size in order to have it map be of the same size as the image.)\n",
    "\n",
    "$$S=\\frac{1}{3} \\left(\\mathcal{N}(\\bar{\\mathcal{I}})+\\mathcal{N}(\\bar{C})+\\mathcal{N}(\\bar{O})\\right) \\quad (8)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S = cv2.resize(1/3 * (normalize(Ibar) + normalize(Cbar) + normalize(Obar)), img.shape[1::-1])\n",
    "plt.imsave('132_saliency.png', S, cmap='gray')\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.set_title('saliency map')\n",
    "ax1.imshow(S, cmap='gray')\n",
    "ax1.axis('off')\n",
    "ax2 = plt.subplot(122)\n",
    "ax2.set_title('originial image')\n",
    "ax2.imshow(img)\n",
    "ax2.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
