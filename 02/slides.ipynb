{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style=\"margin-bottom: 0; padding-bottom: 0;\"><center>The Computational Model</center></h1><h2 style=\"margin: 0; padding: 0;\"><center>Saliency-Based Visual Attention</center></h2>\n",
    "\n",
    "<p><small>Sebastian Höffner &amp; Alexander Höreth<br /><i>November 21, 2016</i></small></p>\n",
    "\n",
    "<p><small><b>Laurent Itti, Christof Koch, Ernst Niebur</b>: A Model of Saliency-Based Visual Attention for Rapid Scene Analysis. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, Vol 20, No 11, pp. 1254&ndash;1259. 1998.</p>\n",
    "\n",
    "<p><small>Image credit goes to the paper if not otherwise mentioned.</small></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import order_filter, convolve2d\n",
    "from os.path import splitext, basename\n",
    "\n",
    "def draw(x, y, i, img, title=''):\n",
    "    ax = plt.subplot(x, y, 0 + i)\n",
    "    ax.axis('off')\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(title)\n",
    "\n",
    "def _make_pyramids(img):\n",
    "    pyramids = [img]\n",
    "    for i in range(8):\n",
    "        pyramids.append(cv2.pyrDown(pyramids[-1]))\n",
    "    return pyramids\n",
    "\n",
    "def toDegree(rad):\n",
    "    return rad * (180/np.pi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Model Architecture\n",
    "\n",
    "<img src=\"architecture.png\" alt=\"Model architecture\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# impath = '640x480/test0.jpg'\n",
    "# impath = '384x384/test1.jpg'\n",
    "# impath = '384x384/test2.jpg'\n",
    "# impath = '500x357/voc2012_000122.jpg'\n",
    "# impath = '500x357/voc2012_000138.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Input Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "impath = '640x480/test0.jpg'\n",
    "img = plt.imread(impath)\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Filtering <small>(level 1)</small>\n",
    "\n",
    "<img src=\"linearfiltering.png\" alt=\"Linear Filtering\" style=\"width: 60%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Color Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "r, g, b = (img[:, :, 0], img[:, :, 1], img[:, :, 2])\n",
    "\n",
    "draw(2, 2, 1, r, 'red')\n",
    "draw(2, 2, 2, g, 'green')\n",
    "draw(2, 2, 3, b, 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def _normalize_channel(nom, denom):\n",
    "    threshold = 0.1*np.max(denom)\n",
    "    nom = np.copy(nom)\n",
    "    yes = np.where(denom > threshold)\n",
    "    nom[np.where(denom <= threshold)] = 0\n",
    "    nom[yes] = nom[yes] / denom[yes]\n",
    "    return nom\n",
    "\n",
    "I = (r + g + b) / 3\n",
    "r, g, b = (_normalize_channel(c, I) for c in (r, g, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Broadly-Tuned Color Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "R = r - (g + b) / 2\n",
    "G = g - (r + b) / 2\n",
    "B = b - (r + g) / 2\n",
    "Y = (r + g) / 2 - np.abs(r - g) / 2 - b\n",
    "\n",
    "draw(2, 2, 1, R, 'red')\n",
    "draw(2, 2, 2, G, 'green')\n",
    "draw(2, 2, 3, B, 'blue')\n",
    "draw(2, 2, 4, Y, 'yellow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Color Channel Feature Pyramids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Rp, Gp, Bp, Yp = (_make_pyramids(m) for m in (R, G, B, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "colors = ('red', 'green', 'blue', 'yellow')\n",
    "for x, layers in enumerate(zip(Rp, Gp, Bp, Yp)):\n",
    "    for y, layer in enumerate(layers):\n",
    "        draw(9, 4, 1+(x*4)+y, layer, colors[y] if x==0 else '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Intensity Image Feature Pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "I = (r + g + b) / 3\n",
    "Ip = _make_pyramids(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "for i, layer in enumerate(Ip): \n",
    "    draw(3, 3, i+1, layer, '%dx%d' % layer.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Gabor Cells\n",
    "\n",
    "Using gabor cells in 4 different orientations to approximate the receptive field orientation sensitivity profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "orientations = np.arange(0, np.pi, np.pi/4)\n",
    "getKernel = lambda t: cv2.getGaborKernel((32, 32), sigma=2, theta=t, lambd=10, gamma=.5, psi=0)\n",
    "gabors = [getKernel(theta) for theta in orientations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "for i, gabor in enumerate(gabors):\n",
    "    draw(2, 2, i+1, gabor, 'theta = %s' % toDegree(orientations[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Orientation Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_gray = np.dot(img[..., :3], [.299, .587, .114])\n",
    "Os = [cv2.filter2D(img_gray, -1, gabor) for gabor in gabors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "for i, O in enumerate(Os):\n",
    "    draw(2, 2, i+1, O, 'theta = %s' % toDegree(orientations[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Orientation Feature Pyramids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ops = [_make_pyramids(O) for O in Os]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "for x, layers in enumerate(zip(*Ops)):\n",
    "    for y, layer in enumerate(layers):\n",
    "        draw(9, 4, 1+(x*4)+y, layer, 'theta = %s' % toDegree(orientations[y]) if x==0 else '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Feature Maps Recap\n",
    "* 6 for intensity contrast - mammals: dark centers bright surrounds or vice-versa\n",
    "* 12 for color - mammals: excitation by one color, inhibition by opposite color\n",
    "* 24 for orientation - mammals: primary visual cortex has layers to detect orientations\n",
    "    * = 42 feature maps\n",
    "    \n",
    "<img src=\"linearfiltering.png\" alt=\"Linear Filtering\" style=\"width: 60%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Center-Surround Differences <small>(level 2)</small>\n",
    "\n",
    "<img src=\"centersurrounddifferences.png\" alt=\"Linear Filtering\" style=\"width: 60%;\" />\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\\begin{align}\n",
    "    \\mathcal{I}(c,s) &= |I(c) \\ominus I(s)| & (1) \\\\\n",
    "    \\mathcal{RG}(c,s) &= |(R(c) - G(c)) \\ominus (G(s) - R(s))| & (2) \\\\\n",
    "    \\mathcal{BY}(c, s) &= |(B(c) - Y(c)) \\ominus (Y(s) - B(s))| & (3) \\\\\n",
    "    O(c,s,\\theta) &= |O(c,\\theta) \\ominus O(s,\\theta)| & (4) \\\\\n",
    "\\end{align}\n",
    "<p>&nbsp;</p>\n",
    "<center>$a \\ominus b$: <i>Interpolate $b$ to the size of $a$ (the bigger image) and do a point-wise subtraction</i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Combinations\n",
    "The following prove well for most images:\n",
    "$$(c, s) \\in \\{ (2, 5), (2, 6), (3, 6), (3, 7), (4, 7), (4, 8) \\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "cs = np.asarray([(2,5), (2,6), (3,6), (3,7), (4,7), (4,8)])-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def _center_surround_diff(c, s, a, b=None):\n",
    "    l = a[c] - (b[c] if b is not None else 0)\n",
    "    r = a[s] if b is None else b[s] - a[s]\n",
    "    return (np.abs(l - cv2.resize(r, l.shape[::-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Intensity and Colors\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\\begin{align}\n",
    "    \\mathcal{I}(c,s) &= |I(c) \\ominus I(s)|\\\\\n",
    "    \\mathcal{RG}(c,s) &= |(R(c) - G(c)) \\ominus (G(s) - R(s))|\\\\\n",
    "\\end{align}\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Ics = [_center_surround_diff(c, s, Ip) for c, s in cs]\n",
    "RGcs = [_center_surround_diff(c, s, Rp, Gp) for c, s in cs]\n",
    "BYcs = [_center_surround_diff(c, s, Bp, Yp) for c, s in cs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "differences = ('intensity', 'red/green', 'blue/yellow')\n",
    "for x, diffs in enumerate(zip(Ics, RGcs, BYcs)):\n",
    "    for y, diff in enumerate(diffs):\n",
    "        draw(6, 3, 1+(x*3)+y, diff, differences[y] if x==0 else '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Orientations\n",
    "\n",
    "\\begin{align}\n",
    "    O(c,s,\\theta) &= |O(c,\\theta) \\ominus O(s,\\theta)|\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Otcs = [[_center_surround_diff(c, s, Op) for c, s in cs] for Op in Ops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "for x, diffs in enumerate(zip(*Otcs)):\n",
    "    for y, diff in enumerate(diffs):\n",
    "        draw(6, 4, 1+(x*4)+y, diff, 'theta = %s' % toDegree(orientations[y]) if x==0 else '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Normalizations\n",
    "\n",
    "- Find maximum $M$ in image\n",
    "- Compute average $\\bar{m}$ of all other local maxima $m_i$\n",
    "- Multiply map by $(M-\\bar{m})^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _normalize(img):\n",
    "    M = np.max(img)\n",
    "    kernel = np.ones((3, 3), dtype=np.int)\n",
    "    filtered = order_filter(img, kernel, np.sum(kernel) - 1)\n",
    "    m = np.mean(img[np.equal(np.equal(img, filtered), filtered != M)])\n",
    "    return img * ((M - m) ** 2)\n",
    "\n",
    "Ics = [_normalize(img) for img in Ics]\n",
    "RGcs = [_normalize(img) for img in RGcs]\n",
    "BYcs = [_normalize(img) for img in BYcs]\n",
    "Otcs = [[_normalize(img) for img in Ocs] for Ocs in Otcs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Center-Surround Differences Recap\n",
    "\n",
    "<img src=\"centersurrounddifferences.png\" alt=\"Linear Filtering\" style=\"width: 60%;\" />\n",
    "\n",
    "<center>42 maps total</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Across-Scale Combinations <small>(level 3)</small>\n",
    "\n",
    "<img src=\"acrossscalecombinations.png\" alt=\"Linear Filtering\" style=\"width: 60%;\" />\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\\begin{align}\n",
    "\\bar{\\mathcal{I}} &= \\oplus^4_{c=2} \\oplus^{c+4}_{s=c+3} \\mathcal{N}(I(c,s))\\\\\n",
    "\\bar{C} &= \\oplus^4_{c=2} \\oplus^{c+4}_{s=c+3} [\\mathcal{N}(\\mathcal{RG}(c,s)) + \\mathcal{N}(\\mathcal{BY}(c,s))]\\\\\n",
    "\\bar{O} &= \\sum_{\\theta \\in \\{0^{\\circ},45^{\\circ},90^{\\circ},135^{\\circ}\\}} \\mathcal{N} \\left( \\oplus^4_{c=2} \\oplus^{c+4}_{s=c+3} \\mathcal{N}(O(c,s,\\theta)) \\right)\\\\\n",
    "\\end{align}\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _addition(imgs, size):\n",
    "    imgs = [cv2.resize(img, size[::-1]) for img in imgs]\n",
    "    return np.sum(imgs, 0)\n",
    "\n",
    "Ibar = _addition(Ics, Ics[3].shape)\n",
    "Cbar = _addition([RGcs[i] + BYcs[i] for i in range(len(RGcs))], RGcs[3].shape)\n",
    "Obar = np.sum([_normalize(_addition(Ocs, Ics[3].shape)) for Ocs in Otcs], 0)\n",
    "\n",
    "draw(1, 3, 1, Ibar, 'Intensity')\n",
    "draw(1, 3, 2, Cbar, 'Color')\n",
    "draw(1, 3, 3, Obar, 'Orientation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Saliency Map Combination\n",
    "\n",
    "<img src=\"architecture.png\" alt=\"Model architecture\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Combine Conspicuity Maps to Saliency Map\n",
    "$$S=\\frac{1}{3} \\left(\\mathcal{N}(\\bar{\\mathcal{I}})+\\mathcal{N}(\\bar{C})+\\mathcal{N}(\\bar{O})\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S = 1/3 * _normalize(Ibar) + _normalize(Cbar) + _normalize(Obar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "draw(1, 2, 1, S, 'Saliency Map')\n",
    "draw(1, 2, 2, img, 'Input Image')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
